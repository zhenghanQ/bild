{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regions = dict(\n",
    "    \n",
    "    lfp = [\n",
    "        \"ctx_lh_S_front_sup.nii.gz\",\n",
    "        \"ctx_lh_G_precentral.nii.gz\",\n",
    "        \"ctx_lh_G_front_middle.nii.gz\",\n",
    "        \"ctx_lh_G_and_S_cingul-Ant.nii.gz\"\n",
    "    ],\n",
    "    \n",
    "    rfp = [\n",
    "        \"ctx_rh_G_front_sup.nii.gz\",\n",
    "        \"ctx_rh_G_postcentral.nii.gz\",\n",
    "        \"ctx_rh_G_front_middle.nii.gz\",\n",
    "        \"ctx_rh_G_front_inf-Orbital.nii.gz\",\n",
    "        \"ctx_rh_G_and_S_transv_frontopol.nii.gz\",\n",
    "        \"ctx_rh_G_precentral.nii.gz\",\n",
    "        \"ctx_rh_S_front_middle.nii.gz\",\n",
    "        \"ctx_rh_G_and_S_cingul-Ant.nii.gz\"\n",
    "    ],\n",
    "    \n",
    "    lt = [\n",
    "        \"ctx_lh_S_temporal_inf.nii.gz\",\n",
    "        \"ctx_lh_G_temp_sup-G_T_transv.nii.gz\",\n",
    "        \"ctx_lh_G_temporal_middle.nii.gz\",\n",
    "        \"ctx_lh_G_temp_sup-Plan_polar.nii.gz\",\n",
    "        \"ctx_lh_G_temp_sup-Lateral.nii.gz\",\n",
    "        \"ctx_lh_G_temporal_inf.nii.gz\",\n",
    "        \"ctx_lh_G_temp_sup-Plan_tempo.nii.gz\",\n",
    "        \"ctx_lh_S_temporal_sup.nii.gz\"\n",
    "    ],\n",
    "    \n",
    "    rt = [\n",
    "        \"ctx_rh_G_temp_sup-Lateral.nii.gz\",\n",
    "        \"ctx_rh_S_temporal_transverse.nii.gz\",\n",
    "        \"ctx_rh_G_temp_sup-Plan_polar.nii.gz\",\n",
    "        \"ctx_rh_G_temporal_middle.nii.gz\",\n",
    "        \"ctx_rh_S_temporal_sup.nii.gz\",\n",
    "        \"ctx_rh_G_temp_sup-Plan_tempo.nii.gz\",\n",
    "        \"ctx_rh_G_temporal_inf.nii.gz\",\n",
    "        \"ctx_rh_S_temporal_inf.nii.gz\",\n",
    "        \"ctx_rh_G_temp_sup-G_T_transv.nii.gz\"\n",
    "    ],\n",
    "    \n",
    "    sc = [\n",
    "        \"Right-Thalamus-Proper.nii.gz\",\n",
    "        \"Left-Thalamus-Proper.nii.gz\",\n",
    "        \"Right-Accumbens-area.nii.gz\",\n",
    "        \"Left-Accumbens-area.nii.gz\",\n",
    "        \"Right-Caudate.nii.gz\",\n",
    "        \"Left-Caudate.nii.gz\",\n",
    "        \"Right-Putamen.nii.gz\",\n",
    "        \"Left-Putamen.nii.gz\",\n",
    "        \"Right-Amygdala.nii.gz\",\n",
    "        \"Left-Amygdala.nii.gz\",\n",
    "        \"Right-Hippocampus.nii.gz\",\n",
    "        \"Left-Hippocampus.nii.gz\"\n",
    "    ]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "voxels = pd.read_csv(\"fszstatcope2_nvoxels_nz.csv\", index_col=0)\n",
    "behav = pd.read_csv(\"behav.txt\", sep='\\t', index_col=0)\n",
    "print(np.mean(behav.index == voxels.index)) #should be 1.0\n",
    "behav2g = behav[np.logical_or(behav.young_kid == 1, behav.adult == 1)]\n",
    "data2g = voxels[np.logical_or(behav.young_kid == 1, behav.adult == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def projection(data , covars):\n",
    "    \"\"\"for removing linear effect of covariates\"\"\"\n",
    "    X, C = data.values, covars.values\n",
    "    P = np.eye(C.shape[0]) - C.dot(np.linalg.pinv(C.T.dot(C))).dot(C.T)\n",
    "    return pd.DataFrame(P.dot(X), columns=data.columns, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest_model(data, y, cv, clf):\n",
    "    X, P = data.values, data.shape[1]\n",
    "    results = dict(pred=[], ytrue=[], fi=[], fidx=[])\n",
    "    results_null = dict(pred=[], ytrue=[], fi=[], fidx=[])\n",
    "    \n",
    "    for idx, (train, test) in enumerate(cv.split(X, y)):   \n",
    "        clf.fit(X[train], y[train])\n",
    "        results[\"pred\"].append(clf.predict(X[test]))\n",
    "        results[\"ytrue\"].append(y[test])\n",
    "        results[\"fi\"].append(clf.feature_importances_)\n",
    "        results[\"fidx\"].append([True for i in range(P)])\n",
    "        \n",
    "        # this is to compute the null model\n",
    "        try:\n",
    "            y_shuff = np.copy(y[train])\n",
    "            np.random.shuffle(y_shuff)\n",
    "            clf.fit(X[train], y_shuff)\n",
    "            results_null[\"pred\"].append(clf.predict(X[test]))\n",
    "            results_null[\"ytrue\"].append(y[test])\n",
    "            results_null[\"fi\"].append(clf.feature_importances_)\n",
    "            results_null[\"fidx\"].append([True for i in range(P)])\n",
    "        except:\n",
    "            print(\"couldn't compute null model\")\n",
    "        \n",
    "    \n",
    "    roc = roc_auc_score(np.array(results[\"ytrue\"]).ravel(), np.array(results[\"pred\"]).ravel())\n",
    "    \n",
    "    # this is to compute the null model\n",
    "    try:\n",
    "        roc_null = roc_auc_score(\n",
    "            np.array(results_null[\"ytrue\"]).ravel(),\n",
    "            np.array(results_null[\"pred\"]).ravel()\n",
    "        )\n",
    "    except:\n",
    "        print(\"couldn't compute null roc score\")\n",
    "        \n",
    "    return results, roc, results_null, roc_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 118)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lfp', 'rfp', 'lt', 'rt', 'sc'])\n"
     ]
    }
   ],
   "source": [
    "data_sets = {}\n",
    "\n",
    "for key, group in regions.items():\n",
    "    data_sets[key] = projection(\n",
    "        data2g.loc[:, group], \n",
    "        behav2g.loc[:, [\"gender\", \"iq\", \"composite_motion\"]]\n",
    "    )\n",
    "\n",
    "print(data_sets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "niters=10\n",
    "rocs = {\"lfp\":[], \"rfp\":[], \"lt\":[], \"rt\":[], \"sc\":[]}\n",
    "rocs_null = {\"lfp\":[], \"rfp\":[], \"lt\":[], \"rt\":[], \"sc\":[]}\n",
    "res = {\"lfp\":[], \"rfp\":[], \"lt\":[], \"rt\":[], \"sc\":[]}\n",
    "res_null = {\"lfp\":[], \"rfp\":[], \"lt\":[], \"rt\":[], \"sc\":[]}\n",
    " \n",
    "for key, val in data_sets.items():\n",
    "    for i_iter in np.arange(niters):\n",
    "        cv=LeaveOneOut()\n",
    "        clf=RandomForestClassifier(n_estimators=1000)\n",
    "        \n",
    "        res_g, roc_g, resnull_g, rocnull_g = random_forest_model(\n",
    "            val, \n",
    "            behav2g.young_kid.values,\n",
    "            cv,\n",
    "            clf\n",
    "        )\n",
    "        \n",
    "        rocs[key].append(roc_g)\n",
    "        rocs_null[key].append(rocnull_g)\n",
    "        res[key].append(res_g)\n",
    "        res_null[key].append(resnull_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lfp': [0.44999999999999996,\n",
       "  0.5272727272727273,\n",
       "  0.6554545454545453,\n",
       "  0.43272727272727274,\n",
       "  0.5672727272727274,\n",
       "  0.44454545454545447,\n",
       "  0.5072727272727273,\n",
       "  0.48454545454545456,\n",
       "  0.6181818181818183,\n",
       "  0.4218181818181818],\n",
       " 'rfp': [0.5527272727272727,\n",
       "  0.4645454545454546,\n",
       "  0.47272727272727266,\n",
       "  0.5472727272727274,\n",
       "  0.5781818181818182,\n",
       "  0.5700000000000001,\n",
       "  0.4245454545454545,\n",
       "  0.4872727272727273,\n",
       "  0.5527272727272727,\n",
       "  0.55],\n",
       " 'lt': [0.48454545454545456,\n",
       "  0.580909090909091,\n",
       "  0.4645454545454546,\n",
       "  0.5527272727272727,\n",
       "  0.5927272727272728,\n",
       "  0.6072727272727273,\n",
       "  0.43909090909090914,\n",
       "  0.600909090909091,\n",
       "  0.3990909090909091,\n",
       "  0.42727272727272725],\n",
       " 'rt': [0.3936363636363637,\n",
       "  0.3590909090909091,\n",
       "  0.55,\n",
       "  0.4645454545454546,\n",
       "  0.4818181818181818,\n",
       "  0.5072727272727273,\n",
       "  0.4645454545454546,\n",
       "  0.4954545454545454,\n",
       "  0.44454545454545447,\n",
       "  0.51],\n",
       " 'sc': [0.6527272727272727,\n",
       "  0.5327272727272727,\n",
       "  0.49909090909090914,\n",
       "  0.5327272727272727,\n",
       "  0.5872727272727273,\n",
       "  0.5527272727272727,\n",
       "  0.44454545454545447,\n",
       "  0.47636363636363643,\n",
       "  0.5127272727272727,\n",
       "  0.4190909090909091]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocs_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lfp', 'rfp', 'lt', 'rt', 'sc'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = LeaveOneOut()\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "ypred = []\n",
    "ytrue = []\n",
    "\n",
    "X = data_sets[\"lfp\"].values\n",
    "y = behav2g.young_kid.values.copy()\n",
    "for train, test in cv.split(X, y):\n",
    "    clf.fit(X[train], y[train])\n",
    "    ypred.append(clf.predict(X[test]))\n",
    "    ytrue.append(y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754545454545453\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    roc_auc_score(\n",
    "        np.array(ytrue).ravel(), \n",
    "        np.array(ypred).ravel()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754545454545453\n"
     ]
    }
   ],
   "source": [
    "cv = LeaveOneOut()\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "ypred = []\n",
    "ytrue = []\n",
    "\n",
    "X = data_sets[\"rfp\"].values\n",
    "y = behav2g.young_kid.values.copy()\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    clf.fit(X[train], y[train])\n",
    "    ypred.append(clf.predict(X[test]))\n",
    "    ytrue.append(y[test])\n",
    "    \n",
    "print(\n",
    "    roc_auc_score(\n",
    "        np.array(ytrue).ravel(), \n",
    "        np.array(ypred).ravel()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754545454545453\n"
     ]
    }
   ],
   "source": [
    "cv = LeaveOneOut()\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "ypred = []\n",
    "ytrue = []\n",
    "\n",
    "X = data_sets[\"lt\"].values\n",
    "y = behav2g.young_kid.values.copy()\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    clf.fit(X[train], y[train])\n",
    "    ypred.append(clf.predict(X[test]))\n",
    "    ytrue.append(y[test])\n",
    "    \n",
    "print(\n",
    "    roc_auc_score(\n",
    "        np.array(ytrue).ravel(), \n",
    "        np.array(ypred).ravel()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754545454545453\n"
     ]
    }
   ],
   "source": [
    "cv = LeaveOneOut()\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "ypred = []\n",
    "ytrue = []\n",
    "\n",
    "X = data_sets[\"rt\"].values\n",
    "y = behav2g.young_kid.values.copy()\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    clf.fit(X[train], y[train])\n",
    "    ypred.append(clf.predict(X[test]))\n",
    "    ytrue.append(y[test])\n",
    "    \n",
    "print(\n",
    "    roc_auc_score(\n",
    "        np.array(ytrue).ravel(), \n",
    "        np.array(ypred).ravel()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754545454545453\n"
     ]
    }
   ],
   "source": [
    "cv = LeaveOneOut()\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "ypred = []\n",
    "ytrue = []\n",
    "\n",
    "X = data_sets[\"sc\"].values\n",
    "y = behav2g.young_kid.values.copy()\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    clf.fit(X[train], y[train])\n",
    "    ypred.append(clf.predict(X[test]))\n",
    "    ytrue.append(y[test])\n",
    "    \n",
    "print(\n",
    "    roc_auc_score(\n",
    "        np.array(ytrue).ravel(), \n",
    "        np.array(ypred).ravel()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfp \t (47, 4)\n",
      "rfp \t (47, 8)\n",
      "lt \t (47, 8)\n",
      "rt \t (47, 9)\n",
      "sc \t (47, 12)\n"
     ]
    }
   ],
   "source": [
    "for key, val in data_sets.items():\n",
    "    print(key, \"\\t\", val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24980795, 0.24923482, 0.25047727, 0.25047995])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res[\"lfp\"][0][\"fi\"]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12510914, 0.12562666, 0.12444553, 0.12474343, 0.12428653,\n",
       "       0.12534908, 0.12557131, 0.12486831])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res[\"rfp\"][0][\"fi\"]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12570894, 0.12456601, 0.12540947, 0.12450691, 0.12459881,\n",
       "       0.12457208, 0.12568254, 0.12495524])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res[\"lt\"][0][\"fi\"]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10977668, 0.11120313, 0.11143813, 0.11147274, 0.11126023,\n",
       "       0.11164601, 0.1108153 , 0.11071083, 0.11167695])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res[\"rt\"][0][\"fi\"]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0828093 , 0.08318331, 0.08328274, 0.0836781 , 0.08349906,\n",
       "       0.08294614, 0.08366214, 0.08359392, 0.08316498, 0.08311352,\n",
       "       0.08359311, 0.08347369])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res[\"sc\"][0][\"fi\"]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
