{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pylab\n",
    "from nilearn.plotting import plot_stat_map\n",
    "import nipype.interfaces.utility as util\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Project Vars:\n",
    "#data_dir=os.path.abspath('/om/user/cdla/projects/bild/openfmri/')\n",
    "data_dir=os.path.abspath('/Users/cdla/Desktop/bild/')\n",
    "l1_dir=os.path.join(data_dir, 'l1output')\n",
    "subj_prefix= 'BILD*'\n",
    "fs_dir=os.path.join(data_dir,'surfaces')\n",
    "template=os.path.join(data_dir,'scripts')\n",
    "data_dir=os.path.join(data_dir,'openfmri')\n",
    "model=1\n",
    "task=1\n",
    "runs=[0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_key = os.path.join(data_dir, 'task_key.txt')\n",
    "task_contrasts = os.path.join(data_dir, 'models', 'model%03d'%model, 'task_contrasts.txt')\n",
    "condition_key = os.path.join(data_dir, 'models', 'model%03d'%model, 'condition_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_tasks(l1_dir,task_key):\n",
    "    with open(task_key, 'r') as f:\n",
    "        tasks = [line.split()[0] for line in f]\n",
    "    for task in tasks:\n",
    "        if os.path.exists(os.path.join(l1_dir,'model%03d'%model,'task%03d'%task)) != True:\n",
    "            tasks = sorted(os.listdir(os.path.join(l1_dir,'model%03d'%model)))\n",
    "    return tasks\n",
    "\n",
    "def get_subjlist(l1_dir,subj_prefix,model, task):\n",
    "    subj_list= [os.path.basename(x) for x in sorted(glob(os.path.join(l1_dir,'model%03d'%model,'task%03d'%task,subj_prefix)))]\n",
    "    return subj_list\n",
    "\n",
    "def get_datalist(l1_dir,subj_prefix):\n",
    "    subj_list = [os.path.basename(x) for x in sorted(glob(os.path.join(data_dir,subj_prefix)))]\n",
    "    return subj_list\n",
    "\n",
    "def get_runs(task, subj_list):\n",
    "    runs_list = []\n",
    "    for subj in subjlist:\n",
    "        task_runs = sorted(os.listdir(os.path.join(openfmri_dir,subj,'BOLD')))\n",
    "        num_runs = 0\n",
    "        for run in task_runs:\n",
    "            if run.split('_')[0] == task:\n",
    "                num_runs += 1\n",
    "        runs_list.append(num_runs)\n",
    "    return runs_list\n",
    "\n",
    "def get_num_vols(bold_file):\n",
    "    bold_img = nb.load(bold_file)\n",
    "    num_vols = bold_img.shape[3]\n",
    "    return num_vols\n",
    "\n",
    "def plot_contrasts(data_dir,l1_dir,model,task,subj):\n",
    "    anat=os.path.join(data_dir,subj,'anatomy','T1_001.nii.gz')\n",
    "    contrasts=sorted(glob(os.path.join(l1_dir,'model%03d'%model,'task%03d'%task,subj,'zstat','zstat*')))\n",
    "    for contrast in contrasts:\n",
    "        plot_stat_map(contrast, anat, threshold=1.6, title=contrast)\n",
    "        print 'test'\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 0 subjects in the data_dir\n",
      "there are 0 finished subjects.\n",
      "there are 0 unfinished subjects.\n",
      "Unfinished subjs are:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#print finished subjs\n",
    "#print unfinished subjs\n",
    "finished_subj_list=get_subjlist(l1_dir,subj_prefix,model,task)\n",
    "total_subjs=get_datalist(l1_dir,subj_prefix)\n",
    "unfinished_subjs=[x for x in total_subjs if x not in finished_subj_list]\n",
    "print 'there are %d subjects in the data_dir'%len(total_subjs)\n",
    "print 'there are %d finished subjects.'%len(finished_subj_list)\n",
    "print 'there are %d unfinished subjects.'%len(unfinished_subjs)\n",
    "print 'Unfinished subjs are:'\n",
    "print unfinished_subjs\n",
    "subj_list=finished_subj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1f7d0ef001de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#visualize model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msubj\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msubj_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mruns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         model_files=sorted(glob(os.path.join(l1_dir,'model%03d'%model,'task%03d'%task,subj,'qa',\n\u001b[0;32m      5\u001b[0m                                         'model','model%03d'%model,'task%03d'%task,'run%02d_run%01d.png'%(run+1,run))))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#visualize model\n",
    "for subj in [subj_list[0]]:\n",
    "    for run in runs:\n",
    "        model_files=sorted(glob(os.path.join(l1_dir,'model%03d'%model,'task%03d'%task,subj,'qa',\n",
    "                                        'model','model%03d'%model,'task%03d'%task,'run%02d_run%01d.png'%(run+1,run))))\n",
    "        models=pylab.figure()\n",
    "        for idx,model_file in enumerate(model_files):\n",
    "            img=mpimg.imread(model_file)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title('model for run %s for subj %s'%(idx,subj))\n",
    "            idx=idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e3167d5c8bda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mplot_stat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontrast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut_coords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msubj\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msubj_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mplot_contrasts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml1_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#visualize contrasts:\n",
    "def plot_contrasts(data_dir,l1_dir,model,task,subj):\n",
    "    anat=os.path.join(data_dir,subj,'anatomy','T1_001.nii.gz')\n",
    "    contrasts=sorted(glob(os.path.join(l1_dir,'model%03d'%model,'task%03d'%task,subj,'zstats','zstat*')))\n",
    "    for contrast in contrasts:\n",
    "        plot_stat_map(contrast, anat, threshold=2.3, title=contrast, display_mode='z', cut_coords=7)\n",
    "        plot_stat_map(contrast, anat, threshold=2.3, title=contrast, display_mode='x', cut_coords=7)\n",
    "        plot_stat_map(contrast, anat, threshold=2.3, title=contrast, display_mode='y', cut_coords=7)\n",
    "        plt.show()\n",
    "for subj in [subj_list[0]]:    \n",
    "    plot_contrasts(data_dir,l1_dir,model,task,subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-9c025a587dca>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-9c025a587dca>\"\u001b[1;36m, line \u001b[1;32m35\u001b[0m\n\u001b[1;33m    outlier = columns  count\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#stim_corr\n",
    "def stim_corr(subinfo, inpath, sparse, subject_id):\n",
    "    import scipy as scipy\n",
    "    import scipy.io as sio\n",
    "    from scipy.stats.stats import pearsonr\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    alls = []\n",
    "    out_images1 = []\n",
    "    out_images2 = []\n",
    "    output_info = []\n",
    "    \n",
    "    if not sparse:\n",
    "        for j, i in enumerate(subinfo):\n",
    "            c_label = i.conditions\n",
    "            cond = len(i.conditions)\n",
    "            # reg = len(i.regressor_names)\n",
    "        output_path = os.path.abspath(\"Outlier.csv\")\n",
    "        ofile = open(output_path, 'w')\n",
    "        ofile.write(', '.join([\"Subject ID\"]+[\"Run\"]+[\"Outlier All\"]+[\"Outlier in %s\" %c_label[d] for d in range(cond)]))\n",
    "        ofile.write('\\n')\n",
    "        for r in range(len(subinfo)): \n",
    "            run = 'run%s' %(r)\n",
    "            # path = os.path.join(inpath, '_generate_model%d/run%d.mat' %(r,r)) #\n",
    "            if len(subinfo) > 1:\n",
    "                param = np.genfromtxt(inpath[r], skip_header=5)\n",
    "            else:\n",
    "                param = np.genfromtxt(inpath, skip_header=5)\n",
    "            mat = param.shape\n",
    "            columns = param.shape[1]\n",
    "            count = cond+6\n",
    "            outlier = columns  count\n",
    "            out = 'Outlier = %d' %(outlier)\n",
    "            con = 'Conditions = %d' %(cond)\n",
    "            matr = 'Design Matrix Shape = [%d rows, %d columns]' %(mat)\n",
    "            output_info.append([[run, out, con, matr]])\n",
    "            ofile.write(', '.join([str(subject_id)]+[str(r)]+[str(outlier)]))\n",
    "            if outlier > 0:\n",
    "                o = param[:, count:columns]\n",
    "                o_sums = o.sum(axis=1)\n",
    "                param_o = np.column_stack((param, o_sums))\n",
    "                # param_int = param_o.astype(int)\n",
    "                ofile.write(', ')\n",
    "                for i in range(cond):\n",
    "                    c_out = np.sum((param_o[:,i] > 0).astype(int) + (param_o[:,1] > 0.9).astype(int)==2)\n",
    "                    out_c = 'Outlier in %s = %d' %(c_label[i], c_out) \n",
    "                    output_info.append([run, out_c])\n",
    "                    ofile.write('%s, ' %(c_out))\n",
    "            else: \n",
    "                param_o = param\n",
    "                for i in range(cond):\n",
    "                    c_out = 0\n",
    "                    out_c = 'Outlier in %s = %d' %(c_label[i], c_out) \n",
    "                    output_info.append([run, out_c])\n",
    "            ofile.write('\\n')\n",
    "            # compute correlation coefficients\n",
    "            stim_corr = []\n",
    "            p_values = []\n",
    "            #pa = param_o.astype(int)\n",
    "            #pa2 = abs(pa)\n",
    "            for i in range(cond):\n",
    "                # correlate each motion parameter with each (i) condition onset\n",
    "                mp1 = [scipy.stats.pearsonr(param_o[:,(i)], param_o[:,(cond)])]\n",
    "                mp2 = [scipy.stats.pearsonr(param_o[:,(i)], param_o[:,(cond+1)])]\n",
    "                mp3 = [scipy.stats.pearsonr(param_o[:,(i)], param_o[:,(cond+2)])]\n",
    "                mp4 = [scipy.stats.pearsonr(param_o[:,(i)], param_o[:,(cond+3)])]\n",
    "                mp5 = [scipy.stats.pearsonr(param_o[:,(i)], param_o[:,(cond+4)])]\n",
    "                mp6 = [scipy.stats.pearsonr(param_o[:,(i)], param_o[:,(cond+5)])]\n",
    "                # correlate sum of outliers with each (i) condition onset\n",
    "                if outlier > 0:\n",
    "                    out = [scipy.stats.pearsonr(param_o[:,(i)], param_o[:,1])]\n",
    "                    stim_corr.append([[i,mp1[0][0]], [i, mp2[0][0]], [i, mp3[0][0]], [i, mp4[0][0]], [i, mp5[0][0]], [i, mp6[0][0]], [i, out[0][0]]])\n",
    "                    p_values.append([[i,mp1[0][1]], [i, mp2[0][1]], [i, mp3[0][1]], [i, mp4[0][1]], [i, mp5[0][1]], [i, mp6[0][1]], [i, out[0][1]]])\n",
    "                else:\n",
    "                    stim_corr.append([[i,mp1[0][0]], [i, mp2[0][0]], [i, mp3[0][0]], [i, mp4[0][0]], [i, mp5[0][0]], [i, mp6[0][0]]])\n",
    "                    p_values.append([[i,mp1[0][1]], [i, mp2[0][1]], [i, mp3[0][1]], [i, mp4[0][1]], [i, mp5[0][1]], [i, mp6[0][1]]])\n",
    "            # save plot of parameter file (each run)\n",
    "            max1 = np.amax(param_o)\n",
    "            min1 = np.amin(param_o)\n",
    "            fig1 = plt.figure(figsize=(12,6), dpi=80)\n",
    "            fig1_title = plt.title(\"Parameter %s\" %(run))\n",
    "            # fig1_plot1 = plt.plot(param_o[:,0:(0+reg)], color='gray', label= r'$Regressor$')\n",
    "            fig1_plot2 = plt.plot(param_o[:,(0):cond], color='blue', label=r'$Stimulus Onset$')\n",
    "            fig1_plot3 = plt.plot(param_o[:,cond:(cond+6)], color='red', label=r'$Motion Parameter$')\n",
    "\n",
    "            if outlier > 0:\n",
    "                fig1_plot4 = plt.plot(param_o[:,columns], color='yellow', label=r'$Outlier Sum$')\n",
    "\n",
    "            fig1_legend = plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "            fig1_ylim = plt.ylim(min10.5,max1+0.5)\n",
    "\n",
    "            plt.savefig(os.path.abspath('parameter_img_%s.png' %(run)),bbox_extra_artists=(fig1_legend,), bbox_inches='tight')\n",
    "            out_images1.append(os.path.abspath('parameter_img_%s.png'%run))\n",
    "            \n",
    "            # save image of pvalues for correlation coefficients (each run)\n",
    "            p_values_fig = np.asarray(p_values)\n",
    "            fig2 = plt.figure()\n",
    "            fig2_title = plt.title(\"P Values %s\" %(run))\n",
    "            fig2_xticks = plt.xticks([0,1,2,3,4,5,6,7,8,10], c_label)\n",
    "            if outlier > 0:\n",
    "                fig2_yticks = plt.yticks([0,1,2,3,4,5,6], [r'$Motion1$', r'$Motion2$', r'$Motion3$', r'$Motion4$', r'$Motion5$', r'$Motion6$',  r'$OutlierSum$' ])\n",
    "            else: \n",
    "                fig2_yticks = plt.yticks([0,1,2,3,4,5], [r'$Motion1$', r'$Motion2$', r'$Motion3$', r'$Motion4$', r'$Motion5$', r'$Motion6$'])\n",
    "            ps = p_values_fig[:, :, 1]\n",
    "            fig2_image = plt.imshow(ps.T, interpolation='nearest', cmap = plt.get_cmap('seismic_r'), vmin = 0, vmax = 0.1)\n",
    "            cb = plt.colorbar()\n",
    "            plt.savefig(os.path.abspath('p_values_img_%s.png' %(run)))\n",
    "            out_images2.append(os.path.abspath('p_values_img_%s.png'%run))\n",
    "        output1_path = os.path.abspath(\"output_check_%s.txt\" %subject_id)\n",
    "        np.savetxt(output1_path, np.asarray(output_info), fmt='%s')\n",
    "        stim_path = os.path.abspath('stimulus_motion_correlation.csv')\n",
    "        sfile = open(stim_path, 'w')\n",
    "        sfile.write(', '.join([\"Condition\"]+[\"Motion%d\" %d for d in range(6)] + [\"Outliers\"]))\n",
    "        sfile.write('\\n')\n",
    "        for i, line in enumerate(stim_corr):\n",
    "            print line\n",
    "            sfile.write(', '.join([c_label[i]]+[str(l[1]) for l in line]))\n",
    "            sfile.write('\\n')\n",
    "        sfile.close()\n",
    "        p_path = os.path.abspath('p_values_correlation.csv')\n",
    "        pfile = open(p_path,'w')\n",
    "        pfile.write(', '.join([\"Condition\"]+[\"Motion %d\" %d for d in range(6)]+[\"Outliers\"]))\n",
    "        pfile.write('\\n') \n",
    "        for i,line in enumerate(p_values):\n",
    "            print line\n",
    "            pfile.write(', '.join([c_label[i]]+[str(l[1]) for l in line]))\n",
    "            pfile.write('\\n')\n",
    "        pfile.close()\n",
    "        ofile.close()\n",
    "        return output_path, output1_path, out_images1, out_images2, stim_path, p_path\n",
    "            \n",
    "    if sparse:  \n",
    "        for j, i in enumerate(subinfo):\n",
    "            c_label = i.conditions\n",
    "            cond = len(i.conditions)\n",
    "            reg = len(i.regressor_names)\n",
    "        output_path = os.path.abspath(\"Outlier.csv\")\n",
    "        ofile = open(output_path, 'w')\n",
    "        ofile.write(', '.join([\"Subject ID\"]+[\"Run\"]+[\"Outlier All\"]+[\"Outlier in %s\" %c_label[d] for d in range(cond)]))\n",
    "        ofile.write('\\n')        \n",
    "        for r in range(len(subinfo)): \n",
    "            run = 'run%s' %(r)\n",
    "            # path = os.path.join(inpath, '_generate_model%d/run%d.mat' %(r,r)) # \n",
    "            if range(len(subinfo)) > 0:\n",
    "                param = np.genfromtxt(inpath[r], skip_header=5)\n",
    "            else:\n",
    "                param = np.genfromtxt(inpath, skip_header=5)\n",
    "            mat = param.shape\n",
    "            columns = param.shape[1]\n",
    "            count = reg+6+cond\n",
    "            outlier = columnscount\n",
    "            out = 'Outlier = %d' %(outlier)\n",
    "            regs = 'Regressors = %d' %(reg)\n",
    "            con = 'Conditions = %d' %(cond)\n",
    "            matr = 'Design Matrix Shape = [%d rows, %d columns]' %(mat)\n",
    "            output_info.append([[run, out, regs, con, matr]])\n",
    "            ofile.write(', '.join([str(subject_id)]+[str(r)]+[str(outlier)]))\n",
    "            if outlier > 0:\n",
    "                o = param[:, count:columns]\n",
    "                o_sums = o.sum(axis=1)\n",
    "                param_o = np.column_stack((param, o_sums))\n",
    "                ofile.write(', ')\n",
    "                for i in range(cond):\n",
    "                    c_out = np.sum((param_o[:,i+reg+6] > 0).astype(int) + (param_o[:,1] > 0.9).astype(int)==2)\n",
    "                    out_c = 'Outlier in %s = %d' %(c_label[i], c_out) \n",
    "                    output_info.append([run, out_c])\n",
    "                    ofile.write('%s, ' %(c_out))\n",
    "            else: \n",
    "                param_o = param\n",
    "                c_out = 0\n",
    "                ofile.write(', ')\n",
    "                for i in range(cond):\n",
    "                    out_c = 'Outlier in %s = %d' %(c_label[i], c_out) \n",
    "                    output_info.append([run, out_c])\n",
    "                    ofile.write('%s, ' %(c_out))\n",
    "            ofile.write('\\n')\n",
    "\n",
    "            # compute correlation coefficients\n",
    "            stim_corr = []\n",
    "            p_values = []\n",
    "            for i in range(cond):\n",
    "                # correlate each motion parameter with each (i) condition onset\n",
    "                mp1 = [scipy.stats.pearsonr(param_o[:,(reg)], param_o[:,(i+reg+6)])]\n",
    "                mp2 = [scipy.stats.pearsonr(param_o[:,(reg+1)], param_o[:,(i+reg+6)])]\n",
    "                mp3 = [scipy.stats.pearsonr(param_o[:,(reg+2)], param_o[:,(i+reg+6)])]\n",
    "                mp4 = [scipy.stats.pearsonr(param_o[:,(reg+3)], param_o[:,(i+reg+6)])]\n",
    "                mp5 = [scipy.stats.pearsonr(param_o[:,(reg+4)], param_o[:,(i+reg+6)])]\n",
    "                mp6 = [scipy.stats.pearsonr(param_o[:,(reg+5)], param_o[:,(i+reg+6)])]\n",
    "                # correlate sum of outliers with each (i) condition onset\n",
    "                if outlier > 0:\n",
    "                    out = [scipy.stats.pearsonr(param_o[:,1], param_o[:,(i+reg+6)])]\n",
    "                    stim_corr.append([[i,mp1[0][0]], [i, mp2[0][0]], [i, mp3[0][0]], [i, mp4[0][0]], [i, mp5[0][0]], [i, mp6[0][0]], [i, out[0][0]]])\n",
    "                    p_values.append([[i,mp1[0][1]], [i, mp2[0][1]], [i, mp3[0][1]], [i, mp4[0][1]], [i, mp5[0][1]], [i, mp6[0][1]], [i, out[0][1]]])\n",
    "                else:\n",
    "                    stim_corr.append([[i,mp1[0][0]], [i, mp2[0][0]], [i, mp3[0][0]], [i, mp4[0][0]], [i, mp5[0][0]], [i, mp6[0][0]]])\n",
    "                    p_values.append([[i,mp1[0][1]], [i, mp2[0][1]], [i, mp3[0][1]], [i, mp4[0][1]], [i, mp5[0][1]], [i, mp6[0][1]]])\n",
    "            \n",
    "            # save plot of parameter file (each run)\n",
    "            max1 = np.amax(param_o)\n",
    "            min1 = np.amin(param_o)\n",
    "            fig1 = plt.figure(figsize=(12,6), dpi=80)\n",
    "            fig1_title = plt.title(\"Parameter %s\" %(run))\n",
    "            fig1_plot1 = plt.plot(param_o[:,0:(0+reg)], color='gray', label= r'$Regressor$')\n",
    "            fig1_plot2 = plt.plot(param_o[:,reg:(reg+6)], color='red', label=r'$Motion Parameter$')\n",
    "            fig1_plot3 = plt.plot(param_o[:,(reg+6):count], color='blue', label=r'$Stimulus Onset$')\n",
    "            if outlier > 0:\n",
    "                fig1_plot4 = plt.plot(param_o[:,columns], color='yellow', label=r'$Outlier Sum$')\n",
    "\n",
    "            fig1_legend = plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "            fig1_ylim = plt.ylim(min10.5,max1+0.5)\n",
    "\n",
    "            plt.savefig(os.path.abspath('parameter_img_%s.png' %(run)),bbox_extra_artists=(fig1_legend,), bbox_inches='tight')\n",
    "            out_images1.append(os.path.abspath('parameter_img_%s.png'%run))\n",
    "            \n",
    "            # save image of pvalues for correlation coefficients (each run)\n",
    "            p_values_fig = np.asarray(p_values)\n",
    "            fig2 = plt.figure()\n",
    "            fig2_title = plt.title(\"P Values %s\" %(run))\n",
    "            fig2_xticks = plt.xticks([0,1,2,3,4,5,6,7,8,10], [r'$Cond1$', r'$Cond2$', r'$Cond3$', r'$Cond4$', r'$Cond5$', r'$Cond6$' ])\n",
    "            if outlier > 0:\n",
    "                fig2_yticks = plt.yticks([0,1,2,3,4,5,6], [r'$Motion1$', r'$Motion2$', r'$Motion3$', r'$Motion4$', r'$Motion5$', r'$Motion6$',  r'$OutlierSum$' ])\n",
    "            else: \n",
    "                fig2_yticks = plt.yticks([0,1,2,3,4,5], [r'$Motion1$', r'$Motion2$', r'$Motion3$', r'$Motion4$', r'$Motion5$', r'$Motion6$'])\n",
    "             ps = p_values_fig[:, :, 1]\n",
    "            fig2_image = plt.imshow(ps.T, interpolation='nearest', cmap = plt.get_cmap('seismic_r'), vmin = 0, vmax = 0.1)\n",
    "            cb = plt.colorbar()\n",
    "\n",
    "            plt.savefig(os.path.abspath('p_values_img_%s.png' %(run)))\n",
    "            out_images2.append(os.path.abspath('p_values_img_%s.png'%run))\n",
    "\n",
    "        output1_path = os.path.abspath(\"output_check_%s.txt\" %subject_id)\n",
    "        np.savetxt(output1_path, np.asarray(output_info), fmt='%s')\n",
    "        stim_path = os.path.abspath('stimulus_motion_correlation.csv')\n",
    "        sfile = open(stim_path, 'w')\n",
    "        sfile.write(', '.join([\"Condition\"]+[\"Motion%d\" %d for d in range(6)] + [\"Outliers\"]))\n",
    "        sfile.write('\\n')\n",
    "        for i, line in enumerate(stim_corr):\n",
    "            print line\n",
    "            sfile.write(', '.join([c_label[i]]+[str(l[1]) for l in line]))\n",
    "            sfile.write('\\n')\n",
    "        sfile.close()\n",
    "        p_path = os.path.abspath('p_values_correlation.csv')\n",
    "        pfile = open(p_path,'w')\n",
    "        pfile.write(', '.join([\"Condition\"]+[\"Motion%d\"%d for d in range(6)]+[\"Outliers\"]))\n",
    "        pfile.write('\\n') \n",
    "        for i,line in enumerate(p_values):\n",
    "            print line\n",
    "            pfile.write(', '.join([c_label[i]]+[str(l[1]) for l in line]))\n",
    "            pfile.write('\\n')\n",
    "        pfile.close()\n",
    "        ofile.close()\n",
    "        return output_path, output1_path, out_images1, out_images2, stim_path, p_path\n",
    "\n",
    "motionflow = pe.Workflow('stim_mot')\n",
    "motionflow.base_dir=os.path.join(os.getcwd(),'stim_cor_working')\n",
    "stim_mot = pe.Node(util.Function(input_names=['subinfo', 'inpath', 'sparse', 'subject_id'],\n",
    "                                output_names=['output_path', 'output1_path', 'out_images1', 'out_images2', 'stim_path', 'p_path'],\n",
    "                                function=stim_corr), name='stim_motion')\n",
    "stim_mot.inputs.sparse = c.is_sparse\n",
    "datagrabber = c.datagrabber.create_dataflow()\n",
    "sink = pe.Node(nio.DataSink(), name='sink')\n",
    "sink.inputs.base_directory = c.sink_dir\n",
    "subjects = datagrabber.get_node('subject_id_iterable')\n",
    "motionflow.connect(subjects,'subject_id',sink,'container')\n",
    "subjectinfo = pe.Node(util.Function(input_names=['subject_id'], output_names=['output']), name='subjectinfo')\n",
    "subjectinfo.inputs.function_str = c.subjectinfo\n",
    "def getsubs(subject_id):#from config import getcontrasts, get_run_numbers, subjectinfo, fwhm\n",
    "        \n",
    "    subs = [('_subject_id_%s/'%subject_id,'')]\n",
    "\n",
    "    return subs\n",
    "\n",
    "get_substitutions = pe.Node(util.Function(input_names=['subject_id'],\n",
    "    output_names=['subs'], function=getsubs), name='getsubs')\n",
    "\n",
    "motionflow.connect(subjects,'subject_id',get_substitutions,'subject_id')\n",
    "motionflow.connect(get_substitutions,\"subs\",sink,\"substitutions\")\n",
    "motionflow.connect(datagrabber, 'datagrabber.input_files', stim_mot, 'inpath')\n",
    "motionflow.connect(subjects,'subject_id',stim_mot,'subject_id')\n",
    "motionflow.connect(subjectinfo,'output', stim_mot, 'subinfo')\n",
    "motionflow.connect(subjects,'subject_id',subjectinfo,'subject_id')\n",
    "motionflow.connect(stim_mot, 'output_path', sink, 'Stimulus_Motion.@file1')\n",
    "motionflow.connect(stim_mot, 'output1_path', sink, 'Stimulus_Motion.@file2')\n",
    "motionflow.connect(stim_mot,'out_images1',sink,'Stimulus_Motion.@images1')\n",
    "motionflow.connect(stim_mot,'out_images2',sink,'Stimulus_Motion.@images2')\n",
    "motionflow.connect(stim_mot,'stim_path',sink,'Stimulus_Motion.@parameter')\n",
    "motionflow.connect(stim_mot,'p_path',sink,'Stimulus_Motion.@pvalues')\n",
    "motionflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualize conditions and hpf\n",
    "hpf=120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dice coefficient between normed anat and template, and normed epi\n",
    "normed_epi=\n",
    "normed_anat=\n",
    "masked_template=\n",
    "\n",
    "dice = np.sum(seg[gt==k])*2.0 / (np.sum(seg) + np.sum(gt))\n",
    "\n",
    "print 'Dice similarity score is {}'.format(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-11-f1b31f894b0c>, line 113)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-f1b31f894b0c>\"\u001b[1;36m, line \u001b[1;32m113\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       \n^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#visualize outliers (run art at several different levels)\n",
    "def plot_timeseries(roi,statsfile,TR,plot,onsets,units):\n",
    "    \"\"\" Returns a plot of an averaged timeseries across an roi\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    roi : List of ints\n",
    "          List of integers corresponding to roi's in the Freesurfer LUT\n",
    "    statsfile : File\n",
    "                File output of segstats workflow\n",
    "    TR : Float\n",
    "         TR of scan\n",
    "    plot : Boolean\n",
    "           True to return plot\n",
    "           \n",
    "    Returns\n",
    "    -------\n",
    "    File : Filename of plot image, if plot=True \n",
    "    List : List of average ROI value if plot=False\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    stats = np.recfromcsv(statsfile)     \n",
    "    \n",
    "    LUT = np.genfromtxt(os.path.join(os.environ[\"FREESURFER_HOME\"],'FreeSurferColorLUT.txt'),dtype = str)\n",
    "    roinum = LUT[:,0]\n",
    "    roiname = LUT[:,1]\n",
    "    Fname = []\n",
    "    AvgRoi = []\n",
    "    \n",
    "    if roi == ['all']:\n",
    "        roi = []\n",
    "        for i, r in enumerate(stats):\n",
    "            roi.append(list(r)[0]) \n",
    "    \n",
    "    for R in roi:\n",
    "        temp = False\n",
    "        #ghetto for loop: find index of roi in stats list\n",
    "        for i, r in enumerate(stats):\n",
    "            if list(r)[0] == R:\n",
    "                temp = True\n",
    "                break    \n",
    "        \n",
    "        if temp:\n",
    "            #find roi name for plot title\n",
    "            title = roiname[roinum==str(np.int_(R))][0]\n",
    "            if plot:\n",
    "                nums = np.asarray(list(stats[i])[1:])\n",
    "                X = np.array(range(len(nums)))*TR\n",
    "                plt.figure(1)\n",
    "                plt.plot(X,nums)\n",
    "                if onsets:\n",
    "                    # onsets is a Bunch with \"conditions\", \"onsets\" and \"durations\".\n",
    "                    print onsets\n",
    "                    names = onsets.conditions\n",
    "                    durations = onsets.durations\n",
    "                    onsets = onsets.onsets\n",
    "                    colors1 = [[]]*len(onsets)\n",
    "\n",
    "                    for i, ons in enumerate(onsets):\n",
    "                        colors1[i] = [np.random.rand(3)]\n",
    "                        if units == 'scans':\n",
    "                            plt.plot(np.asarray(ons)*TR,nums[ons],marker='*',linestyle='None',color=colors1[i][0])\n",
    "                        else:\n",
    "                            plt.plot(ons,nums[np.int_(np.asarray(ons)/TR)],marker='*',linestyle='None',color=colors1[i][0])\n",
    "\n",
    "                    plt.legend(['signal']+names)\n",
    "\n",
    "                    for i, ons in enumerate(onsets):\n",
    "                        ons = np.asarray(ons)\n",
    "                        newX = np.zeros(nums.shape)\n",
    "                        newX[:] = np.nan\n",
    "                        for d in xrange(durations[i][0]):\n",
    "                            if units == 'scans':\n",
    "                                newX[np.int_(ons+np.ones(ons.shape)*(d))] = nums[np.int_(ons+np.ones(ons.shape)*(d))]\n",
    "                            else:\n",
    "                                newX[np.int_(ons/TR)] = nums[np.int_(ons/TR)]\n",
    "                        plt.plot(X,newX,color=colors1[i][0])\n",
    "\n",
    "\n",
    "                plt.title(title)\n",
    "                plt.xlabel('time (s)')\n",
    "                plt.ylabel('signal')\n",
    "\n",
    "                fname = os.path.join(os.getcwd(),os.path.split(statsfile)[1][:-4]+'_'+title+'.png')\n",
    "                plt.savefig(fname,dpi=200)\n",
    "                plt.close()\n",
    "                Fname.append(fname)\n",
    "            else:\n",
    "                AvgRoi.append([title,np.mean(list(stats[i])[1])])\n",
    "        else:\n",
    "            print \"roi %s not found!\"%R\n",
    "\n",
    "    return Fname, AvgRoi\n",
    "    \n",
    "    def plot_ADnorm(ADnorm,TR,norm_thresh,out):\n",
    "    \"\"\" Returns a plot of the composite_norm file output from art\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ADnorm : File\n",
    "             Text file output from art\n",
    "    TR : Float\n",
    "         TR of scan\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    File : Filename of plot image\n",
    "    \n",
    "    \"\"\"\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    if not isinstance(out,list):\n",
    "        out = [out]\n",
    "\n",
    "    plot = os.path.abspath('plot_'+os.path.split(ADnorm)[1]+'.png')\n",
    "    \n",
    "    data = np.genfromtxt(ADnorm)\n",
    "    plt.figure(1,figsize = (8,3))\n",
    "    X = np.array(range(data.shape[0]))*TR\n",
    "    plt.plot(X,data)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Composite Norm')\n",
    "    \n",
    "    if norm_thresh > max(data):\n",
    "        plt.axis([0,TR*data.shape[0],0,norm_thresh*1.1])\n",
    "        plt.plot(X,np.ones(X.shape)*norm_thresh)\n",
    "        for o in out:\n",
    "            plt.plot(o*TR*np.ones(2),[0,norm_thresh*1.1],'r-')\n",
    "    else:\n",
    "        plt.axis([0,TR*data.shape[0],0,max(data)*1.1])\n",
    "        plt.plot(X,np.ones(X.shape)*norm_thresh)\n",
    "        for o in out:\n",
    "            plt.plot(o*TR*np.ones(2),[0,max(data)*1.1],'r-')\n",
    "    \n",
    "    plt.savefig(plot,bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return plot\n",
    "    \n",
    "    def art_output(art_file,intensity_file,stats_file):\n",
    "    import numpy as np\n",
    "    from nipype.utils.filemanip import load_json\n",
    "    import os\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        out=np.asarray(np.genfromtxt(art_file))\n",
    "    except:\n",
    "        out=np.asarray([])\n",
    "    table=[[\"file\",art_file],[\"num outliers\", str(out.shape)],[\"timepoints\",str(out)]]\n",
    "    stats = load_json(stats_file)\n",
    "    for s in stats:\n",
    "        for key, item in s.iteritems():\n",
    "            if isinstance(item,dict):\n",
    "                table.append(['+'+key,''])\n",
    "                for sub_key,sub_item in item.iteritems():\n",
    "                    table.append(['  '+sub_key,str(sub_item)])\n",
    "            elif isinstance(item, list):\n",
    "                table.append(['+'+key,''])\n",
    "                for s_item in item:\n",
    "                    for sub_key, sub_item in s_item.iteritems():\n",
    "                        table.append(['  '+sub_key,str(sub_item)])\n",
    "            else:\n",
    "                table.append([key,str(item)])\n",
    "    print table\n",
    "    intensity = np.genfromtxt(intensity_file)\n",
    "    intensity_plot = os.path.abspath('global_intensity.png')\n",
    "    plt.figure(1,figsize = (8,3))\n",
    "    plt.xlabel('Volume')\n",
    "    plt.ylabel(\"Global Intensity\")\n",
    "    plt.plot(intensity)\n",
    "    plt.savefig(intensity_plot,bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return table, out.tolist(), intensity_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot meanfunc/anat in func space\n",
    "#plot mni mean func/ mni normed anat/ mni template\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
